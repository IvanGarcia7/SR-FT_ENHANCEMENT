{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFM_codigo_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "deteccionesckpt2",
      "language": "python",
      "name": "deteccionesckpt2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gAj7xV8TN7o"
      },
      "source": [
        "# **IMPORTACIÓN DE LAS LIBRERÍAS NECESARIAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk1-4DySTN7r"
      },
      "source": [
        "import collections.abc\n",
        "import collections\n",
        "import cv2\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pathlib\n",
        "import pylab\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import time as time\n",
        "import wget\n",
        "import zipfile\n",
        "\n",
        "from cv2 import dnn_superres\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from time import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl9WI582TN7v"
      },
      "source": [
        "# **FUNCIONES AUXILIARES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-ugMW1WUcjc"
      },
      "source": [
        "### Función definida para facilitar la creación de directorios de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWzc6TxoTN7v"
      },
      "source": [
        "def create_dir(path):\n",
        "  try: \n",
        "      if not os.path.exists(path):\n",
        "        os.makedirs(path) \n",
        "      else:\n",
        "        shutil.rmtree(path, ignore_errors=True)\n",
        "        os.makedirs(path)  \n",
        "  except OSError: \n",
        "      print ('Error creando la carpeta con la ruta ',path,' .')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL_aY2vzV1h4"
      },
      "source": [
        "### Función definida para conocer el tamaño de las imágenes procesadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuqRRg7qV56q"
      },
      "source": [
        "def know_dimensions(path):\n",
        "  img = cv2.imread(path)\n",
        "  height, width, channels = img.shape\n",
        "  print(height, width, channels)\n",
        "\n",
        "IMAGE_PATH_VANILLA = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/butterfly1.jpg'\n",
        "know_dimensions(IMAGE_PATH_VANILLA)\n",
        "\n",
        "IMAGE_PATH_SR = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/butterfly2.jpg'\n",
        "know_dimensions(IMAGE_PATH_SR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhQG2DC9XXuX"
      },
      "source": [
        "### Función definida para cargar una imagen a un numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRuofvTkXbfE"
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "    return np.array(Image.open(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceq1o1qpbNQi"
      },
      "source": [
        "### Se activa la asignación de memoria dinámica de la GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb4LZX6ybL3h"
      },
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    \n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')           \n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPPC2cCdcesL"
      },
      "source": [
        "### Funciones definidas para aplicar el modelo pre-entrenado de super-resolución. createsr se ha definido para aplicar sr además de disminución de ruido mientras que createsr1 aplica única y exclusivamente super resolución. en base al estudio realizado, a lo largo del trabajo se utilizará createsr, función la cual aplica disminución de ruido, ya que esta aumenta y mejora el número de detecciones obtenidas por el modelo neuronal convolucional junto con SR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhhRJ0m2cb8n"
      },
      "source": [
        "def createSR(image_path):\n",
        "  IMAGE_ORIGINAL_PATH = image_path\n",
        "  IMAGE_SR_PATH = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0_SR.png'\n",
        "  PATH_TO_MODEL_DIR = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/MODEL_SR/FSRCNN_x2.pb'\n",
        "  sr = dnn_superres.DnnSuperResImpl_create()\n",
        "  image = cv2.imread(IMAGE_ORIGINAL_PATH)\n",
        "  sr.readModel(PATH_TO_MODEL_DIR)\n",
        "  sr.setModel(\"fsrcnn\", 2)\n",
        "  result = sr.upsample(image)\n",
        "  cv2.imwrite(IMAGE_SR_PATH, result)\n",
        "  img = cv2.imread('/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0_SR.png')\n",
        "  dst = cv2.fastNlMeansDenoisingColored(img,None,8,8,7,11)\n",
        "  cv2.imwrite('/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0D_SR.png', dst) \n",
        "\n",
        "def createSR1(image_path):\n",
        "  IMAGE_ORIGINAL_PATH = image_path\n",
        "  IMAGE_SR_PATH = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0D_SR.png'\n",
        "  PATH_TO_MODEL_DIR = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/MODEL_SR/FSRCNN_x2.pb'\n",
        "  sr = dnn_superres.DnnSuperResImpl_create()\n",
        "  image = cv2.imread(IMAGE_ORIGINAL_PATH)\n",
        "  sr.readModel(PATH_TO_MODEL_DIR)\n",
        "  sr.setModel(\"fsrcnn\", 2)\n",
        "  result = sr.upsample(image)\n",
        "  cv2.imwrite(IMAGE_SR_PATH, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-DJsKLfTN7v"
      },
      "source": [
        "# **APLICACIÓN DE PROCESOS DE SUPER-RESOLUCIÓN (SR)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKQwjUMfU5Fe"
      },
      "source": [
        "### Ejemplo definido para establecer como hacer uso del modelo de SR a la hora de procesar las imágenes requeridas. En este caso se ha hecho uso del modelo pre-entrenado FSRCNN con un factor de amplicación x2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BFqFBKBTN7w"
      },
      "source": [
        "def download_model_SR(model_name):\n",
        "    data_dir = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/MODEL_SR'\n",
        "    create_dir(data_dir)\n",
        "    base_url = 'https://github.com/Saafke/FSRCNN_Tensorflow/blob/master/models/'\n",
        "    model_file = base_url+ model_name +'.pb?raw=true'\n",
        "    download_model = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/MODEL_SR/\"+model_name+'.pb'\n",
        "    wget.download(model_file, download_model) \n",
        "    return download_model\n",
        "\n",
        "def download_images(url_path):\n",
        "    data_dir = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/'\n",
        "    create_dir(data_dir)\n",
        "    download_image = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/butterfly1.jpg'\n",
        "    wget.download(url_path, download_image) \n",
        "    return download_image\n",
        "\n",
        "MODEL_NAME = 'FSRCNN_x2'\n",
        "PATH_TO_MODEL_DIR = download_model_SR(MODEL_NAME)\n",
        "IMAGE_PATH = 'https://www.sciencemag.org/sites/default/files/styles/article_main_large/public/butterfly_16x9_0.jpg?itok=jZ3DYvGK'\n",
        "download_images(IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vd-iadnTN7x"
      },
      "source": [
        "MODEL_NAME = 'FSRCNN_x2'\n",
        "PATH_TO_MODEL_DIR = download_model_SR(MODEL_NAME)\n",
        "\n",
        "data_dir = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/'\n",
        "create_dir(data_dir) \n",
        "data_dir = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/'\n",
        "create_dir(data_dir) \n",
        "\n",
        "sr = dnn_superres.DnnSuperResImpl_create()\n",
        "image = cv2.imread('/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/butterfly1.jpg')\n",
        "sr.readModel(PATH_TO_MODEL_DIR)\n",
        "sr.setModel(\"fsrcnn\", 2)\n",
        "result = sr.upsample(image)\n",
        "cv2.imwrite('/usr/share/Data2/objectos_pequeños/PRINCIPAL/data/butterfly2.jpg', result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1k_gYvUTN7z"
      },
      "source": [
        "# **APLICACIÓN DEL MODELO DE DETECCIÓN DE OBJETOS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bMBFO7xTN7z"
      },
      "source": [
        "path = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/\"\n",
        "path_instalation = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/master.zip\"\n",
        "try:\n",
        "    shutil.rmtree(path, ignore_errors=True)\n",
        "    os.mkdir(path)\n",
        "    path_download = \"https://github.com/tensorflow/models/archive/master.zip\"\n",
        "    wget.download(path_download, path_instalation)\n",
        "    fantasy_zip = zipfile.ZipFile(path_instalation)\n",
        "    fantasy_zip.extractall(path)\n",
        "    fantasy_zip.close() \n",
        "    os.rename(\"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/models-master\", \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/models\")\n",
        "    os.remove(path_instalation)\n",
        "except OSError:\n",
        "    print (\"El directorio que se pretende borrar no existe\" % path)\n",
        "else:\n",
        "    print (\"Directorio de trabajo generado correctamente %s \" % path)\n",
        "os.chdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKtm8i9mTN70"
      },
      "source": [
        "# **GENERACIÓN DEL ESPACIO EN EL CUAL SE ALMACENARÁN LAS IMÁGENES A INFERIR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bE5zsiCTN71"
      },
      "source": [
        "path = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATA\"\n",
        "create_dir(path)\n",
        "os.chdir(path)\n",
        "\n",
        "path = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS\"\n",
        "create_dir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVTv5uviTN71"
      },
      "source": [
        "# **DESCARGA DEL MODELO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dStbEo7NWPX3"
      },
      "source": [
        "### Función definida para establecer la descarga del modelo, siendo en este caso Efficientdet D4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I27n1EyxTN71"
      },
      "source": [
        "def download_model(model_name, model_date):\n",
        "    base_url = 'http://download.tensorflow.org/models/object_detection/tf2/'\n",
        "    model_file = model_name + '.tar.gz'\n",
        "    model_dir = tf.keras.utils.get_file(fname=model_name,\n",
        "                                        origin=base_url + model_date + '/' + \n",
        "                                        model_file,\n",
        "                                        untar=True)\n",
        "    return str(model_dir)\n",
        "\n",
        "MODEL_DATE = '20200711'\n",
        "MODEL_NAME = 'efficientdet_d4_coco17_tpu-32'\n",
        "PATH_TO_MODEL_DIR = download_model(MODEL_NAME, MODEL_DATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Ku2TSsTN72"
      },
      "source": [
        "# **DESCARGA DE LAS ETIQUETAS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ZxhEY-Whu7"
      },
      "source": [
        "### Función definida para establecer la descarga de las etiquetas, siendo en este caso el labelmap de COCO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juZgvfp5TN72",
        "outputId": "7b4f7c11-c39b-446f-e9be-bf7819e35cc2"
      },
      "source": [
        "def download_labels(filename):\n",
        "    base_url = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/'\n",
        "    label_dir = tf.keras.utils.get_file(fname=filename,\n",
        "                                        origin=base_url + filename,\n",
        "                                        untar=False)\n",
        "    label_dir = pathlib.Path(label_dir)\n",
        "    return str(label_dir)\n",
        "\n",
        "LABEL_FILENAME = 'mscoco_complete_label_map.pbtxt'\n",
        "PATH_TO_LABELS = download_labels(LABEL_FILENAME)\n",
        "print(PATH_TO_LABELS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ivangarcia/.keras/datasets/mscoco_complete_label_map.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diAx0j4OTN72"
      },
      "source": [
        "# **CARGA DEL MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aubJXLQ6TN72"
      },
      "source": [
        "import time\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkiVxErpTN73"
      },
      "source": [
        "# **CARGA DE LAS ETIQUETAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVRlSfBkTN73"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BnJzfCFTN73"
      },
      "source": [
        "# **EVALUACIÓN DEL MODELO INICIAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBENdFsGTN75"
      },
      "source": [
        "matplotlib.use('Agg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytg9haLzXqBU"
      },
      "source": [
        "### Array definido para almacenar los tiempos de detección."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BriAZVqgXuLU"
      },
      "source": [
        "tiempos_procesar_deteccion = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw7MAyKqTN75"
      },
      "source": [
        "def make_RAW_inference(image_path,counter,image_save):\n",
        "  '''APLICO LA DETECCIÓN DE ELEMENTOS'''\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "  tiempos_procesar_deteccion.append(elapsed_time)\n",
        "  \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()} \n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  '''ALMACENO LAS BBOXES,CLASES Y PUNTUACIONES EN SUS RESPECTIVAS LISTAS'''\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "    boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "    scores_filter.append(detections['detection_scores'][item])\n",
        "    classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "  '''VISUALIZO Y ALMACENO EL RESULTADO OBTENIDO'''\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=100,\n",
        "        min_score_thresh=.3,\n",
        "        agnostic_mode=False,\n",
        "        line_thickness=1)\n",
        "  plt.axis('off')\n",
        "\n",
        "  dpi=300\n",
        "  nombre = counter\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  plt.savefig(image_save+nombre,  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "  \n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  '''FILTRO LAS DETECCIONES POR UNA PUNTUACIÓN MÍNIMA DADA COMO ENTRADA'''\n",
        "\n",
        "  min_score_thresh = .3\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "\n",
        "  salida = []\n",
        "  salida.append(true_boxes.tolist())\n",
        "  salida.append(true_scores.tolist())\n",
        "  salida.append(true_clases.tolist()) \n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  width, height = image.size\n",
        "  salida.append(width)\n",
        "  salida.append(height)\n",
        "\n",
        "  return salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTEH2reYf6z"
      },
      "source": [
        "### Creo los directorios en los cuales se almacenarán los resultados obtenidos tras aplicar la red neuronal convolucional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBvnSIJaTN76"
      },
      "source": [
        "create_dir('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS')\n",
        "create_dir('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s_UvlfRY0t8"
      },
      "source": [
        "### La función make_RAW_inference toma tres parámetros como entrada, la imagen sobre la cual se desea aplicar las detecciones de los elementos provistos por el modelo neuronal convolucional pre-entrenado, el nombre con el cual se almacenará dicho resultado, así como la ruta sobre la cual se desea almacenar los mismos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgXdjPcATN77"
      },
      "source": [
        "make_RAW_inference('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/1.jpg','1.jpg','/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzBg1uW1TN78"
      },
      "source": [
        "# **INICIALIZACIÓN DEL DICCIONARIO DE NOMBRES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzWWNdBkZKQn"
      },
      "source": [
        "### Con el fin de medir posteiormente el mAP (mean Average Precision) obtenido con el evaluador de COCO, es necesario definir previamente un diccionario de nombres con el objetivo de realizar dicha métrica correctamente. En primer lugar se carga el JSON el cual contiene las detecciones con los GT y se realiza una correlación entre el nombre de la imagen y su respectivo id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukx13eDmTN79"
      },
      "source": [
        "jsonString = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/annotations/instances_default.json'\n",
        "diccionario_ids = {}\n",
        "\n",
        "with open(jsonString) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for p3 in data['images']:\n",
        "        data_s_image = p3['file_name']\n",
        "        data_s_id = p3['id']\n",
        "        diccionario_ids[data_s_image] = data_s_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlLpV2BJTN79"
      },
      "source": [
        "# **CREACIÓN DE LAS ANOTACIONES CON EL MODELO BASE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4SMF2URTN79"
      },
      "source": [
        "imagenes_dir = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images'\n",
        "contenido = os.listdir(imagenes_dir)\n",
        "counter = 0\n",
        "result = []\n",
        "tiempos_procesar = []\n",
        "out = []\n",
        "contador_veces = 0\n",
        "\n",
        "for fichero2 in contenido2:\n",
        "  '''APLICO UNA EXPRESIÓN REGULAR PARA OBTENER EL NOMBRE DE LA IMAGEN A PROCESAR'''\n",
        "  x = re.search(\"[1-9]+[0-9]*\", fichero2)\n",
        "  id = x.group(0)\n",
        "  image_path_gg = \"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images/{}\".format(fichero2)\n",
        "\n",
        "  '''APLICO LA DETECCIÓN DE ELEMENTOS CON LA FUNCIÓN DEFINIDA ANTERIORMENTE'''\n",
        "  start_time = time.time()\n",
        "  salida = make_RAW_inference(image_path_gg,fichero2,'/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/')\n",
        "  elapsed_time = time.time() - start_time\n",
        "  tiempos_procesar.append(elapsed_time)\n",
        "\n",
        "  contador_veces = contador_veces+1\n",
        "  print(\"Numero de veces que se ha ejecutado: \"+str(contador_veces))\n",
        "  result = []\n",
        "  converted_num = int(id)\n",
        "\n",
        "  '''OBTENGO EL ID CORRESPONDIENTE A DICHA IMAGEN'''\n",
        "  converted_num = diccionario_ids[fichero2]\n",
        "  print(fichero2, \" \",converted_num)\n",
        "\n",
        "  width = salida[3]\n",
        "  height = salida[4]\n",
        "  boxes2 = []\n",
        "\n",
        "  for box in salida[0]:\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "    '''\n",
        "    TRANSFORMO LAS COORDENADAS INICIALES YA QUE ESTAS DEBEN ESTAR EN EL FORMATO\n",
        "    DE COCO ADECUADO, SIENDO ESTE (XMIN,YMIN,WIDTH,HEIGHT).\n",
        "    '''\n",
        "\n",
        "    box_new = []\n",
        "    box_new.append(xmin)\n",
        "    box_new.append(ymin)\n",
        "    box_new.append(xmax-xmin)\n",
        "    box_new.append(ymax-ymin)\n",
        "  \n",
        "    boxes2.append(box_new)\n",
        "   \n",
        "\n",
        "  '''VOY GENERANDO UN JSON CON LAS DETECCIONES OBTENIDAS POR CADA IMAGEN'''\n",
        "  result.extend(\n",
        "        [\n",
        "            {\n",
        "                \"image_id\": converted_num,\n",
        "                \"category_id\": salida[2][k],\n",
        "                \"bbox\": box,\n",
        "                \"score\": salida[1][k],\n",
        "            }\n",
        "            for k, box in enumerate(boxes2)\n",
        "        ]\n",
        "  )\n",
        "  \n",
        "  for sample in result:    \n",
        "        out.append(sample) \n",
        "\n",
        "'''ALMACENO EL JSON EN UN ARCHIVO PARA SU POSTERIOR EVALUACIÓN'''\n",
        "\n",
        "with open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/test_data_normal-video1.json', 'w', encoding='utf-8') as file:\n",
        "  json.dump(out, file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTUBH-v0TN7_"
      },
      "source": [
        "# **EVALUACIÓN DE LAS ANOTACIONES CON EL MODELO RAW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeZyX-KFTN7_"
      },
      "source": [
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "annType = ['segm','bbox','keypoints']\n",
        "\n",
        "'''SE ESPECIFICA EL TIPO DE DETECCIÓN SIENDO EN ESTE CASO BBOX'''\n",
        "annType = annType[1]\n",
        "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
        "print ('Running demo for *%s* results.'%(annType))\n",
        "\n",
        "'''SE LEE EL JSON EL CUAL CONTIENE LAS ANOTACIONES CON LOS GROUND TRUTH (GT)'''\n",
        "annFile = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video3/annotations/instances_default.json'\n",
        "cocoGt=COCO(annFile)\n",
        "\n",
        "'''SE LEE EL JSON DEFINIDO ANTERIORMENTE CON LAS ANOTACIONES OBTENIDAS POR EL MODELO RAW'''\n",
        "resFile = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/test_data_normal-video1.json'\n",
        "cocoDt=cocoGt.loadRes(resFile)\n",
        "\n",
        "dts = json.load(open(resFile,'r'))\n",
        "imgIds = [imid['image_id'] for imid in dts]\n",
        "imgIds = sorted(list(set(imgIds)))\n",
        "\n",
        "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "cocoEval.params.imgIds  = imgIds\n",
        "\n",
        "'''\n",
        "SE ESTABLECE LA CLASE SOBRE LA CUAL SE DESEA OBTENER EL mAP, SIENDO EN ESTE CASO EL ID 3\n",
        "CORRESPONDIENTE CON LA CLASE COCHE.\n",
        "'''\n",
        "\n",
        "cocoEval.params.catIds = [3] \n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBeQDrZ0TN8A"
      },
      "source": [
        "# **PROPUESTA ESTABLECIDA - APLICACIÓN EXCLUSIVA DE SUPER-RESOLUCIÓN:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3aEN90IdR0A"
      },
      "source": [
        "### Variables definidas para almacenar el número de pasadas requeridas por cada imagen, así como el tiempo necesario para su procesamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TivPgIHXTN8A"
      },
      "source": [
        "array_veces = []\n",
        "tiempos_procesar2 = []\n",
        "auxiliar_tiempos = 0\n",
        "diccionario_tiempos = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcv4Bwo2TN8B"
      },
      "source": [
        "# **DETECCIÓN CON APLICACIÓN EXCLUSIVA DE SUPER-RESOLUCIÓN (SR):**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpQ5StsG8Tc"
      },
      "source": [
        "### Funciones definidas para la creación del cluster de elementos detectados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWZAFbE8TN8B"
      },
      "source": [
        "def rectangle_area(sq):\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA CALCULAR EL ÁREA DE UN RECTÁNGULO.\n",
        "    '''\n",
        "    sq_min_h = sq[0]\n",
        "    sq_max_h = sq[2]\n",
        "    sq_min_w = sq[1]\n",
        "    sq_max_w = sq[3]\n",
        "    \n",
        "    height = sq_max_h - sq_min_h\n",
        "    if height < 0:\n",
        "        return -1\n",
        "    \n",
        "    width = sq_max_w - sq_min_w\n",
        "    if width < 0:\n",
        "        return -1\n",
        "    \n",
        "    return height*width\n",
        "\n",
        "\n",
        "def bbox_to_square(bbox):\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA ESTABLECER EL FORMATO ADECUADO DE LAS BBOX\n",
        "    AL SIGUIENTE -> [XMIN,YMIN.XMAX,YMAX]\n",
        "    '''\n",
        "    ymin,xmin,ymax,xmax = bbox\n",
        "    bbox_adecuada = [ymin,xmin,ymax,xmax]\n",
        "    return bbox_adecuada\n",
        "\n",
        "\n",
        "def obtener_objeto_mas_confiable_idx(lists):\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA OBTENER EL ELEMENTO CON MAYOR PUNTUACIÓN DE ACUERDO\n",
        "    A LA LISTA DADA COMO ENTRADA. DEVUELVE EL ÍNDICE DEL OBJETO SELECCIONADO\n",
        "    Y EL ÍNDICE DE LA LISTA QUE LO CONTENIA.\n",
        "    '''\n",
        "\n",
        "    mayor_puntuacion = None\n",
        "    mayor_puntuacion_objeto_idx = None\n",
        "    mayor_puntuacion_objeto_lista_idx = None\n",
        "    for l_idx, l in enumerate(lists):\n",
        "        _, _, puntuacion = l\n",
        "        lista_actual_con_mayor_puntuacion = puntuacion.max()\n",
        "        if not mayor_puntuacion or mayor_puntuacion < lista_actual_con_mayor_puntuacion:\n",
        "            mayor_puntuacion = lista_actual_con_mayor_puntuacion\n",
        "            mayor_puntuacion_objeto_idx = np.where(puntuacion==mayor_puntuacion)[0][0]\n",
        "            mayor_puntuacion_objeto_lista_idx = l_idx\n",
        "\n",
        "    return mayor_puntuacion_objeto_idx, mayor_puntuacion_objeto_lista_idx\n",
        "\n",
        "\n",
        "def union_de_dos_rectangulos(sq1, sq2):\n",
        "\n",
        "    '''\n",
        "   FUNCIÓN ESTABLECIDA PARA CALCULAR LA UNIÓN DEL ÁREA QUE CONFORMAN DOS RECTÁNGULOS.\n",
        "   '''\n",
        "\n",
        "    sq1_area = rectangle_area(sq1)\n",
        "    sq2_area = rectangle_area(sq2)\n",
        "    \n",
        "    return sq1_area + sq2_area - intersecion_entre_dos_rectangulos(sq1, sq2) \n",
        "\n",
        "\n",
        "def intersecion_entre_dos_rectangulos(sq1, sq2):\n",
        "\n",
        "   '''\n",
        "   FUNCIÓN ESTABLECIDA PARA CALCULAR EL ÍNDICE DE IOU EN BASE AL ÁREA QUE COMPONE\n",
        "   DOS RECTÁNGULOS.\n",
        "   '''\n",
        "   sq1_min_h = sq1[0]\n",
        "   sq1_max_h = sq1[2]\n",
        "   sq1_min_w = sq1[1]\n",
        "   sq1_max_w = sq1[3]\n",
        "   sq2_min_h = sq2[0]\n",
        "   sq2_max_h = sq2[2]\n",
        "   sq2_min_w = sq2[1]\n",
        "   sq2_max_w = sq2[3]\n",
        "    \n",
        "   in_sq_min_h = max(sq1_min_h, sq2_min_h)\n",
        "   in_sq_max_h = min(sq1_max_h, sq2_max_h)\n",
        "   in_sq_min_w = max(sq1_min_w, sq2_min_w)\n",
        "   in_sq_max_w = min(sq1_max_w, sq2_max_w)\n",
        "    \n",
        "   area = rectangle_area([in_sq_min_h, in_sq_min_w, in_sq_max_h, in_sq_max_w])\n",
        "    \n",
        "   if area != -1:\n",
        "     return area\n",
        "   else:\n",
        "     return 0\n",
        "\n",
        "\n",
        "def intersection_over_union_usando_cuadrados(sq1, sq2):\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA CALCULAR EL ÍNDICE DE IOU\n",
        "    '''\n",
        "    intersecion = intersecion_entre_dos_rectangulos(sq1,sq2)\n",
        "    union = union_de_dos_rectangulos(sq1,sq2)\n",
        "    \n",
        "    return intersecion/union\n",
        "\n",
        "\n",
        "def intersection_over_union(bbox1, bbox2):\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA ESTABLECER EL ÍNDICE DE IOU EN BASE A DOS BBOXES\n",
        "    DADOS COMO ENTRADA.\n",
        "\n",
        "    DEVUELVE EL ÍNDICE OBTENIDO.\n",
        "    '''\n",
        "\n",
        "    sq1 = bbox_to_square(bbox1)\n",
        "    sq2 = bbox_to_square(bbox2)\n",
        "\n",
        "    return intersection_over_union_usando_cuadrados(sq1, sq2)\n",
        "\n",
        "\n",
        "def obtener_mismo_objeto(obj, detections_list, threshold, ignore_class = True):\n",
        "\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA OBTENER EL OBJETO MÁS CERCANO DE UNA LISTA DE OBJETOS\n",
        "    EN BASE A UN ÍNDICE DADO COMO ENTRADA (threshold).\n",
        "\n",
        "    EL OBJETO ESTÁ FORMADO POR UNA TUPLA (BBOX,CLASE,PUNTUACIÓN)\n",
        "\n",
        "    IGNORE_CLASS SE DEFINE COMO TRUE PARA IGNORAR CLASES A LA HORA DE ASIGNAR \n",
        "    EQUIVALENCIAS.\n",
        "\n",
        "    DEVUELVE UN ENTERO CON EL ÍNDICE DEL OBJETO CON MAYOR ÍNDICE IOU DE ACUERDO\n",
        "    CON EL ELEMENTO DADO COMO ENTRADA.\n",
        "    '''\n",
        "\n",
        "    lista_bboxes, lista_classes, _ = detections_list\n",
        "    obj_bbox, obj_class, _ = obj\n",
        "    mejor_iou = None\n",
        "    mejor_iou_idx = None\n",
        "\n",
        "    for idx, (bbox, _class) in enumerate(zip(lista_bboxes, lista_classes)):\n",
        "        iou = intersection_over_union(obj_bbox, bbox)\n",
        "        if ignore_class or obj_class == _class:\n",
        "            if iou > threshold and ((not mejor_iou) or iou > mejor_iou):\n",
        "                mejor_iou = iou\n",
        "                mejor_iou_idx = idx\n",
        "\n",
        "    return mejor_iou_idx\n",
        "\n",
        "\n",
        "def create_clusters(_lists, threshold):\n",
        "\n",
        "    '''\n",
        "    FUNCIÓN DEFINIDA PARA CLEAR EL CLUSTER DE ELEMENTOS DETECTADOS ASIGNADNO EQUIVALENCIAS EN BASE\n",
        "    A LAS LISTAS DE TUPLAS DADAS COMO ENTRADA DE ACUERDO CON LAS COORDENADAS DE SUS RESPECTIVAS\n",
        "    BBOXES.\n",
        "\n",
        "    ARGUMENTOS:\n",
        "    _lists ESTÁ FORMADO POR UNA LISTA DE TUPLAS. CADA UNA DE ESTAS POSEE LA SIGUIENTE ESTRUCTURA:\n",
        "    _lists = [(np.array(bbox), np.array(classs), np.array(confidences))]\n",
        "\n",
        "    DEVUELVE UNA LISTA DE TUPLAS [(np.array(bbox), np.array(classs), np.array(confidences))] \n",
        "    EN BASE A LAS COINCIDENCIAS DE CADA OBJETO DETECTADO.\n",
        "    '''\n",
        "\n",
        "    lists = _lists.copy()\n",
        "    lista_vacia_a_eliminar_idx = []\n",
        "    for idx, _list in enumerate(lists):\n",
        "        _, classes, _ = _list\n",
        "        if classes.shape[0] ==0:\n",
        "            lista_vacia_a_eliminar_idx.append(idx)\n",
        "\n",
        "    for lista_vacia_idx in reversed(sorted(lista_vacia_a_eliminar_idx)):            \n",
        "        lists.pop(lista_vacia_idx)\n",
        "\n",
        "    clusters = []   \n",
        "    while len(lists) > 0:\n",
        "        objeto_mas_confiable_idx, lista_objeto_mas_confiable_idx = obtener_objeto_mas_confiable_idx(lists)\n",
        "        lista_objeto_mas_confiable = lists[lista_objeto_mas_confiable_idx]\n",
        "        lista_objeto_mas_confiable_bboxes, lista_objeto_mas_confiable_classes, lista_objeto_mas_confiable_confidences = lista_objeto_mas_confiable\n",
        "\n",
        "        '''CREAMOS UN FILTRO PARA EXCLUIR EL OBJETO DE LAS LISTAS SELECCIONADAS'''\n",
        "        filtro_idx = lista_objeto_mas_confiable_classes.shape[0]*[True]\n",
        "        filtro_idx[objeto_mas_confiable_idx] = False\n",
        "\n",
        "        '''OBTENEMOS EL OBJETO MÁS CONFIABLE Y LO EXCLUIMOS DEL RESTO DE LISTAS'''\n",
        "        bbox_objeto_mas_confiable = lista_objeto_mas_confiable_bboxes[objeto_mas_confiable_idx,:]\n",
        "        lista_objeto_mas_confiable_bboxes = lista_objeto_mas_confiable_bboxes[filtro_idx]\n",
        "        clase_objeto_mas_confiable = lista_objeto_mas_confiable_classes[objeto_mas_confiable_idx]\n",
        "        lista_objeto_mas_confiable_classes = lista_objeto_mas_confiable_classes[filtro_idx]\n",
        "        puntuacion_objeto_mas_confiable = lista_objeto_mas_confiable_confidences[objeto_mas_confiable_idx]\n",
        "        lista_objeto_mas_confiable_confidences = lista_objeto_mas_confiable_confidences[filtro_idx]\n",
        "        assert lista_objeto_mas_confiable_bboxes.shape[0] == lista_objeto_mas_confiable_classes.shape[0] == lista_objeto_mas_confiable_confidences.shape[0]\n",
        "\n",
        "        '''ACTUALIZAMOS LAS LISTAS'''\n",
        "        lists[lista_objeto_mas_confiable_idx] = [lista_objeto_mas_confiable_bboxes, lista_objeto_mas_confiable_classes, lista_objeto_mas_confiable_confidences]\n",
        "\n",
        "        '''SE GENERA LA TUPLA CON EL OBJETO CON MAYOR PUNTUACIÓN'''\n",
        "        objeto_mayor_puntuacion = (bbox_objeto_mas_confiable, clase_objeto_mas_confiable, puntuacion_objeto_mas_confiable)\n",
        "\n",
        "        '''SE INICIALIZA EL CLUSTER DE ELEMENTOS'''\n",
        "        cluster_bboxes = [bbox_objeto_mas_confiable]\n",
        "        cluster_classes = [clase_objeto_mas_confiable]\n",
        "        cluster_confidences = [puntuacion_objeto_mas_confiable]\n",
        "\n",
        "        lista_vacia_a_eliminar_idx = []\n",
        "        '''BUSCAMOS AL ELEMENTO SELECCIONADO EN OTRAS LISTAS'''\n",
        "        for list_idx in range(len(lists)):\n",
        "            if list_idx != lista_objeto_mas_confiable_idx:\n",
        "                lista_actual = lists[list_idx]\n",
        "                \n",
        "                '''OBTENEMOS EL OBJETO CON LA PUNTUACIÓN MÁS CERCANA DE ACUERDO AL ÍNDICE IOU DEFINIDO'''\n",
        "                mismo_objeto_lista_actual_idx = obtener_mismo_objeto(objeto_mayor_puntuacion, lista_actual, threshold)\n",
        "                \n",
        "                '''\n",
        "                SI EL ELEMENTO OBTENIDO ES DISTINTO DE NONE, SE INSERTA EN EL CLUSTER Y SE ELIMINA\n",
        "                DE LA LISTAS.\n",
        "                '''\n",
        "\n",
        "                if not mismo_objeto_lista_actual_idx is None:\n",
        "                    '''OBTENEMOS LA INFORMACIÓN'''\n",
        "                    lista_actual_bboxes, lista_actual_classes, lista_actual_conficendes = lista_actual\n",
        "\n",
        "                    '''LA AÑADIMOS AL CLUSTER DE ELEMENTOS'''\n",
        "                    cluster_bboxes.append(lista_actual_bboxes[mismo_objeto_lista_actual_idx])\n",
        "                    cluster_classes.append(lista_actual_classes[mismo_objeto_lista_actual_idx])\n",
        "                    cluster_confidences.append(lista_actual_conficendes[mismo_objeto_lista_actual_idx])\n",
        "\n",
        "                    '''CREAMOS UN FILTRO PARA ELIMINAR EL OBJETO SELECCIONADO'''\n",
        "                    lista_actual_filtro_idx = lista_actual_classes.shape[0]*[True]\n",
        "                    lista_actual_filtro_idx[mismo_objeto_lista_actual_idx] = False\n",
        "\n",
        "                    '''ACTUALIZAMOS LA INFORMACIÓN DE LA LISTA ACTUAL'''\n",
        "                    lista_actual_bboxes = lista_actual_bboxes[lista_actual_filtro_idx]\n",
        "                    lista_actual_classes = lista_actual_classes[lista_actual_filtro_idx]\n",
        "                    lista_actual_conficendes = lista_actual_conficendes[lista_actual_filtro_idx]\n",
        "                    \n",
        "                    '''\n",
        "                    SI LA LISTA ACTUAL NO ESTÁ VACÍA, LA GUARDAMOS EN CASO CONTRARIO LA AÑADIMOS A \n",
        "                    LAS LISTAS PENDIENTES DE ELIMINAR\n",
        "                    '''\n",
        "                    if lista_actual_classes.shape[0] != 0:\n",
        "                        lista_actual = lista_actual_bboxes, lista_actual_classes, lista_actual_conficendes\n",
        "                        lists[list_idx] = lista_actual\n",
        "                    else:\n",
        "                        lista_vacia_a_eliminar_idx.append(list_idx)\n",
        "\n",
        "        cluster = (np.array(cluster_bboxes), np.array(cluster_classes), np.array(cluster_confidences))\n",
        "        clusters.append(cluster)\n",
        "\n",
        "        if lista_objeto_mas_confiable_classes.shape[0] == 0:\n",
        "            lista_vacia_a_eliminar_idx.append(lista_objeto_mas_confiable_idx)\n",
        "\n",
        "        for lista_vacia_idx in reversed(sorted(lista_vacia_a_eliminar_idx)):            \n",
        "            lists.pop(lista_vacia_idx)\n",
        "\n",
        "    return clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvDFwVfIRB3P"
      },
      "source": [
        "# **IMPLEMENTACIÓN DE LA PROPUESTA EXCLUSIVA DE SUPER-RESOLUCIÓN: PRIMERA VERSIÓN (VERSIÓN PRIMITIVA)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTODhLZeRTkZ"
      },
      "source": [
        "def make_simple_inference_SR(image,counter,x1,y1,diccionario_final_predicciones,\n",
        "                                               diccionario_final_scores,\n",
        "                                               diccionario_final_clases,\n",
        "                                               width,height,auxiliar_tiempos):\n",
        "  print('Running super-inference for {}... '.format(image), end='\\n')\n",
        "  \n",
        "  '''OBTENEMOS LAS DETECCIONES DE LA IMAGEN SR DADA COMO ENTRADA'''\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "    \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "  '''FILTRAMOS LAS DETECCIONES POR UN SCORE PREVIAMENTE ESTABLECIDO'''\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "  min_score_thresh = .4\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "\n",
        "  detections['detection_boxes'] = true_boxes\n",
        "  detections['detection_classes'] = true_clases\n",
        "  detections['detection_scores'] = true_scores\n",
        "  \n",
        "  '''REALIZAMOS LA TRANSFORMACIÓN DE COORDENADAS'''\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "\n",
        "      ymin11 = ((((box_detected[0]*height))+y1)/2)\n",
        "      xmin11 = ((((box_detected[1]*width))+x1)/2)\n",
        "      ymax11 = ((((box_detected[2]*height))+y1)/2)\n",
        "      xmax11 = ((((box_detected[3]*width))+x1)/2)\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11/height)\n",
        "      coordenadas_good.append(xmin11/width)\n",
        "      coordenadas_good.append(ymax11/height)\n",
        "      coordenadas_good.append(xmax11/width)\n",
        "\n",
        "      '''ALMACENAMOS LA INFORMACIÓN EN EL REPSECTIVO DICCIONARIO PASADO COMO ARGUMENTO'''\n",
        "      diccionario_final_predicciones.append(coordenadas_good)\n",
        "      diccionario_final_scores.append(true_scores[i])\n",
        "      diccionario_final_clases.append(true_clases[i])\n",
        "    \n",
        "  \n",
        "def make_inference_SR(image_path,counter,image_save,contador_veces):\n",
        "  contador_veces = contador_veces+1\n",
        "  dpi = 300\n",
        "\n",
        "  print('Running inference for {}... '.format(image_path), end='\\n')\n",
        "\n",
        "  '''GENERAMOS LA IMAGEN SUPER-RESUELTA'''\n",
        "  createSR(image_path)\n",
        "\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  '''OBTENEMOS LAS DETECCIONES DE ACUERDO CON LA IMAGEN DADA COMO ENTRADA'''\n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "  \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()} \n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  '''FILTRAMOS LAS DETECCIONES EN BASE A UNA PUNTUACIÓN PREVIAMENTE ESTABLECIDA'''\n",
        "  min_score_thresh=.2\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "  \n",
        "  '''LEEMOS LA IMAGEN SUPER-RESUELTA GENERADA'''\n",
        "  new_counter = 0\n",
        "  img = cv2.imread(image_path)\n",
        "  im = Image.open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0D_SR.png')\n",
        "\n",
        "  contador_final = 0 \n",
        "  img__READ = cv2.imread(image_path)\n",
        "  height, width, channels = img__READ.shape\n",
        "\n",
        "  diccionario_final_predicciones = []\n",
        "  diccionario_final_scores = []\n",
        "  diccionario_final_clases = []\n",
        "    \n",
        "  contador_veces = contador_veces+len(true_boxes)\n",
        "  array_veces.append(contador_veces)\n",
        "  \n",
        "  '''\n",
        "  PARA CADA UNA DE LAS DETECCIONES, CALCULAMOS SU CENTRO Y GENERAMOS UNA \n",
        "  NUEVA SUBIMAGEN A PARTIR DE LA SUPER-RESUELTA\n",
        "  '''\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "      ymin = int(box_detected[0]*height*2)\n",
        "      xmin = int(box_detected[1]*width*2)\n",
        "      ymax = int(box_detected[2]*height*2)\n",
        "      xmax = int(box_detected[3]*width*2)\n",
        "    \n",
        "      ymin11 = (box_detected[0])\n",
        "      xmin11 = (box_detected[1])\n",
        "      ymax11 = (box_detected[2])\n",
        "      xmax11 = (box_detected[3])\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11)\n",
        "      coordenadas_good.append(xmin11)\n",
        "      coordenadas_good.append(ymax11)\n",
        "      coordenadas_good.append(xmax11)\n",
        "      \n",
        "      diccionario_final_predicciones.append(coordenadas_good)\n",
        "      diccionario_final_scores.append(true_scores[new_counter])\n",
        "      diccionario_final_clases.append(true_clases[new_counter])\n",
        "\n",
        "      a1 = (xmin+xmax)//2\n",
        "      a2 = (ymin+ymax)//2\n",
        "\n",
        "      RECORTEX = int(width/2)\n",
        "      RECORTEY = int(height/2)\n",
        "      \n",
        "      '''\n",
        "      GENERAMOS LA NUEVA IMAGEN OBTENIENDO PÍXELES A LOS LADOS DEL CENTRO DE LA \n",
        "      DETECCIÓN DEL OBJETO.\n",
        "      '''\n",
        "      im_crop_outside = im.crop((a1-RECORTEX, a2-RECORTEY, a1+RECORTEX, a2+RECORTEY))\n",
        "\n",
        "      nombre_sr_2 =\"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/AUX/{}.jpg\".format(str(i))\n",
        "      im_crop_outside.save(nombre_sr_2, quality=100)\n",
        "      \n",
        "      RECORTEX = int(width/2)\n",
        "      RECORTEY = int(height/2)  \n",
        "\n",
        "      'REALIZAMOS UNA NUEVA INFERENCIA POR CADA UNA DE LAS SUBIMAGENES GENERADAS'\n",
        "      score_class = make_simple_inference_SR(nombre_sr_2,new_counter,a1-RECORTEX,a2-RECORTEY,\n",
        "                                           diccionario_final_predicciones,\n",
        "                                           diccionario_final_scores,\n",
        "                                           diccionario_final_clases,\n",
        "                                           width,height,counter )\n",
        "  \n",
        "      new_counter = new_counter+1\n",
        "\n",
        "  detections['detection_boxes'] = np.array(diccionario_final_predicciones)\n",
        "  detections['detection_classes'] = diccionario_final_clases\n",
        "  detections['detection_scores'] = diccionario_final_scores\n",
        "\n",
        "  diccionario_final2_predicciones = []\n",
        "  diccionario_final2_scores = []\n",
        "  diccionario_final2_clases = []\n",
        "\n",
        "  puntero = 0\n",
        "  error = [-1,-1,-1,-1]\n",
        "\n",
        "  '''\n",
        "  LLEGADOS A ESTE PUNTO CALCULAMOS EL IOU DE LOS ELEMENTOS CON EL OBJETIVO\n",
        "  DE ELIMINAR MÚLTIPLES DETECCIONES PARA UN MISMO OBJETO.\n",
        "  '''\n",
        "  \n",
        "  for ia in range(len(diccionario_final_predicciones)):\n",
        "    coordenadas_A = diccionario_final_predicciones[ia]\n",
        "\n",
        "    if diccionario_final_predicciones[ia][0]!=-1:\n",
        "      \n",
        "      diccionario_final2_predicciones.append(diccionario_final_predicciones[ia])\n",
        "      diccionario_final2_scores.append(diccionario_final_scores[ia])\n",
        "      diccionario_final2_clases.append(diccionario_final_clases[ia])\n",
        "\n",
        "      for ib in range(len(diccionario_final_predicciones)):\n",
        "        if ia != ib:\n",
        "          \n",
        "          coordenadas_B = diccionario_final_predicciones[ib]\n",
        "\n",
        "          if diccionario_final_predicciones[ib][0]!=-1:\n",
        "              yminA = max(coordenadas_A[0]*height,coordenadas_B[0]*height)\n",
        "              xminA = max(coordenadas_A[1]*width,coordenadas_B[1]*width)\n",
        "              ymaxA = min(coordenadas_A[2]*height,coordenadas_B[2]*height)\n",
        "              xmaxA = min(coordenadas_A[3]*width,coordenadas_B[3]*width)\n",
        "\n",
        "              interArea = max(0, ymaxA - yminA + 1) * max(0, xmaxA - xminA + 1)\n",
        "\n",
        "              boxAArea = (coordenadas_A[2]*height - coordenadas_A[0]*height + 1) * (coordenadas_A[3]*width - coordenadas_A[1]*width + 1)\n",
        "              boxBArea = (coordenadas_B[2]*height - coordenadas_B[0]*height + 1) * (coordenadas_B[3]*width - coordenadas_B[1]*width + 1)\n",
        "              \n",
        "              iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "              if iou > 0.1:\n",
        "                  contador = len(diccionario_final2_predicciones)-1\n",
        "                  if (diccionario_final2_scores[contador]) < diccionario_final_scores[ib]:\n",
        "                    \n",
        "                    contador = len(diccionario_final2_predicciones)-1\n",
        "                    diccionario_final2_predicciones[contador] = diccionario_final_predicciones[ib]\n",
        "                    diccionario_final2_scores[contador] = diccionario_final_scores[ib]\n",
        "                    diccionario_final2_clases[contador] = diccionario_final_clases[ib]\n",
        "\n",
        "                  diccionario_final_predicciones[ib] = error\n",
        "            \n",
        "  detections['detection_boxes'] = np.array(diccionario_final2_predicciones)\n",
        "  detections['detection_classes'] = diccionario_final2_clases\n",
        "  detections['detection_scores'] = diccionario_final2_scores\n",
        "  \n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "  '''\n",
        "  VISUALIZAMOS LA IMAGEN RESULTANTE TRAS APLICAR LA PROPUESTA DE MEJORA \n",
        "  EXCLUSIVA CON SUPER-RESOLUCIÓN.\n",
        "  '''\n",
        "  \n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=300,\n",
        "        min_score_thresh=.3,\n",
        "        agnostic_mode=False,\n",
        "        line_thickness=1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image_np_with_detections)\n",
        "  \n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  min_score_thresh=.3\n",
        "  img = cv2.imread(image_path)\n",
        "  nombre = counter\n",
        "  plt.savefig('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/'+nombre,  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  '''\n",
        "  DEVOLVEMOS EN LA VARIABLE SALIDA LA LISTA DE BBOXES, CLASES, SCORES, ASÍ COMO\n",
        "  EL ANCHO Y LARGO DE LA IMAGEN DADA COMO ENTRADA.\n",
        "  '''\n",
        "\n",
        "  min_score_thresh = .3\n",
        "  salida = []\n",
        "  salida.append(boxes.tolist())\n",
        "  salida.append(scores[0])\n",
        "  salida.append(clases_detected) \n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  width, height = image.size\n",
        "\n",
        "  salida.append(width)\n",
        "  salida.append(height)\n",
        "  return salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWDLzPOcnuI6"
      },
      "source": [
        "make_inference_SR('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/1.jpg','1.jpg','/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/',0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbuJ6fw0RR_6"
      },
      "source": [
        "# **IMPLEMENTACIÓN DE LA PROPUESTA EXCLUSIVA DE SUPER-RESOLUCIÓN: SEGUNDA VERSIÓN (CLUSTER DE ELEMENTOS)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEkis_ppG6WC"
      },
      "source": [
        "def make_simple_inference_SR(image,counter,x1,y1,width,height,auxiliar_tiempos, LISTA_TRIPLAS):\n",
        "  print('Running super-inference for {}... '.format(image), end='\\n')\n",
        "  dpi = 300\n",
        "  image2 = np.array(Image.open(image))\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  '''OBTENEMOS LAS DETECCIONES PARA LA SUBIMAGEN SUPER-RESUELTA'''\n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "    \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "  \n",
        "  '''FILTRAMOS POR UNA PUNTUACIÓN MÍNIMA PRE-ESTABLECIDA'''\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "  min_score_thresh = .4\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = true_boxes\n",
        "  detections['detection_classes'] = true_clases\n",
        "  detections['detection_scores'] = true_scores\n",
        "    \n",
        "  '''MOSTRAMOS LAS DETECCIONES OBTENIDAS EN LA SUBIMAGEN Y POSTERIORMENTE LA ALMACENAMOS'''\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image2,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=detections.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image2)\n",
        "\n",
        "  min_score_thresh=.4\n",
        "  nombre = counter\n",
        "  plt.savefig('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/FotoAux/'+str(nombre),  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "  \n",
        "  '''CREAMOS LA LISTA QUE CONFORMARÁN LA TUPLA DE DETECCIONES'''\n",
        "  LISTA_BOXES_TRIPLAS = []\n",
        "  LISTA_CLASES_TRIPLAS = []\n",
        "  LISTA_SCORES_TRIPLAS = []\n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "\n",
        "      ymin11 = ((((box_detected[0]*height))+y1)/2)\n",
        "      xmin11 = ((((box_detected[1]*width))+x1)/2)\n",
        "      ymax11 = ((((box_detected[2]*height))+y1)/2)\n",
        "      xmax11 = ((((box_detected[3]*width))+x1)/2)\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11/height)\n",
        "      coordenadas_good.append(xmin11/width)\n",
        "      coordenadas_good.append(ymax11/height)\n",
        "      coordenadas_good.append(xmax11/width)\n",
        "        \n",
        "      LISTA_BOXES_TRIPLAS.append(coordenadas_good)\n",
        "      LISTA_CLASES_TRIPLAS.append(true_clases[i])\n",
        "      LISTA_SCORES_TRIPLAS.append(true_scores[i])\n",
        "      \n",
        "  \n",
        "  \n",
        "  LISTA_TRIPLAS.append((np.array(LISTA_BOXES_TRIPLAS),np.array(LISTA_CLASES_TRIPLAS),np.array(LISTA_SCORES_TRIPLAS)))\n",
        "  \n",
        "  \n",
        "def make_inference_SR(image_path,counter,image_save,contador_veces):\n",
        "  print('Running inference for {}... '.format(image_path), end='\\n')\n",
        "  contador_veces = contador_veces+1\n",
        "  dpi = 300\n",
        "  image2 = np.array(Image.open(image_path))\n",
        "  '''CREAMOS LA IMAGEN SUPER-RESUELTA'''\n",
        "  createSR(image_path)\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  '''APLICAMOS LAS DETECCIONES A LA IMAGEN DADA COMO ENTRADA'''\n",
        "\n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "      \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()} \n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  '''FILTRAMOS LAS DETECCIONES EN BASE A UNA PUNTUACIÓN PRE-DEFINIDA'''\n",
        "  min_score_thresh=.2\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "  \n",
        "  new_counter = 0\n",
        "  img = cv2.imread(image_path)\n",
        "  im = Image.open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0D_SR.png')\n",
        "\n",
        "  contador_final = 0 \n",
        "\n",
        "  img__READ = cv2.imread(image_path)\n",
        "  height, width, channels = img__READ.shape  \n",
        "  contador_veces = contador_veces+len(true_boxes)\n",
        "  array_veces.append(contador_veces)\n",
        "\n",
        "    \n",
        "  LISTA_TRIPLAS = []\n",
        "    \n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "      ymin = int(box_detected[0]*height*2)\n",
        "      xmin = int(box_detected[1]*width*2)\n",
        "      ymax = int(box_detected[2]*height*2)\n",
        "      xmax = int(box_detected[3]*width*2)\n",
        "    \n",
        "      ymin11 = (box_detected[0])\n",
        "      xmin11 = (box_detected[1])\n",
        "      ymax11 = (box_detected[2])\n",
        "      xmax11 = (box_detected[3])\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11)\n",
        "      coordenadas_good.append(xmin11)\n",
        "      coordenadas_good.append(ymax11)\n",
        "      coordenadas_good.append(xmax11)\n",
        "\n",
        "      a1 = (xmin+xmax)//2\n",
        "      a2 = (ymin+ymax)//2\n",
        "\n",
        "      RECORTEX = int(width/2)\n",
        "      RECORTEY = int(height/2)\n",
        "      \n",
        "      '''GENERAMOS LA NUEVA SUBIMAGEN A PARTIR DE LA SUPER-RESUELTA'''\n",
        "      im_crop_outside = im.crop((a1-RECORTEX, a2-RECORTEY, a1+RECORTEX, a2+RECORTEY))\n",
        "\n",
        "      nombre_sr_2 =\"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/AUX/{}.jpg\".format(str(i))\n",
        "      im_crop_outside.save(nombre_sr_2, quality=100)\n",
        "      \n",
        "      RECORTEX = int(width/2)\n",
        "      RECORTEY = int(height/2)  \n",
        "\n",
        "      'VOLVEMOMS A ESTABLECER LA DETECCIÓN DE OBJETOS EN LA NUEVA SUBIMAGEN GENERADA'\n",
        "      \n",
        "      make_simple_inference_SR(nombre_sr_2,new_counter,a1-RECORTEX,a2-RECORTEY,\n",
        "                                           width,height,counter,LISTA_TRIPLAS )\n",
        "      \n",
        "      new_counter = new_counter+1\n",
        "\n",
        "\n",
        "  puntero = 0\n",
        "    \n",
        "  '''GENERAMOS LA LISTA PARA CONFORMAR LA TRIPLA DE LA PASADA INICIAL'''  \n",
        "  LISTA_BOXES_TRIPLAS = []\n",
        "  LISTA_CLASES_TRIPLAS = []\n",
        "  LISTA_SCORES_TRIPLAS = []\n",
        "  contador_triplas = 0\n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "      ymin = int(box_detected[0]*height*2)\n",
        "      xmin = int(box_detected[1]*width*2)\n",
        "      ymax = int(box_detected[2]*height*2)\n",
        "      xmax = int(box_detected[3]*width*2)\n",
        "    \n",
        "      ymin11 = (box_detected[0])\n",
        "      xmin11 = (box_detected[1])\n",
        "      ymax11 = (box_detected[2])\n",
        "      xmax11 = (box_detected[3])\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11)\n",
        "      coordenadas_good.append(xmin11)\n",
        "      coordenadas_good.append(ymax11)\n",
        "      coordenadas_good.append(xmax11)\n",
        "        \n",
        "      LISTA_BOXES_TRIPLAS.append(coordenadas_good)\n",
        "      LISTA_CLASES_TRIPLAS.append(true_clases[contador_triplas])\n",
        "      LISTA_SCORES_TRIPLAS.append(true_scores[contador_triplas])\n",
        "    \n",
        "      \n",
        "      contador_triplas = contador_triplas + 1\n",
        "      \n",
        "\n",
        "  LISTA_TRIPLAS.append((np.array(LISTA_BOXES_TRIPLAS),np.array(LISTA_CLASES_TRIPLAS),np.array(LISTA_SCORES_TRIPLAS)))\n",
        "\n",
        "  \n",
        "  '''OBTENEMOS EL CLUSTER DE ELEMENTOS'''\n",
        "  cluster_final = create_clusters(LISTA_TRIPLAS, threshold =0.1)\n",
        "\n",
        "  \n",
        "  '''\n",
        "  EN BASE A LA LISTA DE TRUPLAS QUE DEVUELVE LA FUNCIÓN CREATE_CLUSTER,\n",
        "  SELECCIONAMOS A LOS ELEMENTOS CON MAYOR PUNTUACIÓN.  \n",
        "  '''\n",
        "\n",
        "  LISTA_BOXES_OK = []\n",
        "  LISTA_CLASES_OK = []\n",
        "  LISTA_SCORES_OK = []\n",
        "    \n",
        "  for indexcluster in range(len(cluster_final)):\n",
        "    tripla = cluster_final[indexcluster]\n",
        "    \n",
        "    lista_boxes_lista = tripla[0].tolist()\n",
        "    lista_clases_lista = tripla[1].tolist()\n",
        "    lista_scores_lista = tripla[2].tolist()\n",
        "    \n",
        "    indice = np.argmax(lista_scores_lista)\n",
        "    LISTA_BOXES_OK.append(lista_boxes_lista[indice])\n",
        "    LISTA_CLASES_OK.append(lista_clases_lista[indice])\n",
        "    LISTA_SCORES_OK.append(lista_scores_lista[indice])\n",
        "      \n",
        "            \n",
        "  detections['detection_boxes'] = np.array(LISTA_BOXES_OK)\n",
        "  detections['detection_classes'] = np.array(LISTA_CLASES_OK)\n",
        "  detections['detection_scores'] = np.array(LISTA_SCORES_OK)\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "     \n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image2,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=300,\n",
        "      min_score_thresh=.3,\n",
        "      agnostic_mode=False,\n",
        "      line_thickness=1)\n",
        "\n",
        "  display(Image.fromarray(image2))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image2)\n",
        "  \n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  min_score_thresh=.3\n",
        "  img = cv2.imread(image_path)\n",
        "  nombre = counter\n",
        "  plt.savefig('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/'+nombre,  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "\n",
        "  clases_detected = detections['detection_classes']\n",
        "  \n",
        "  '''DEVOLVEMOS EN LA VARIABLE SALIDA LAS BBOXES, CLASES Y PUNTUACIONES FINALES OBTENIDAS'''\n",
        "  min_score_thresh = .3\n",
        "  salida = []\n",
        "  salida.append(boxes.tolist())\n",
        "  salida.append(scores[0])\n",
        "  salida.append(clases_detected) \n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  width, height = image.size\n",
        "\n",
        "  salida.append(width)\n",
        "  salida.append(height)\n",
        "  return salida"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDWj5SQnnuI7"
      },
      "source": [
        "make_inference_SR('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/1.jpg','1.jpg','/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/',0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTGzrVrCTN8C"
      },
      "source": [
        "# **IMPLEMENTACIÓN DE LA PROPUESTA EXCLUSIVA DE SUPER-RESOLUCIÓN: TERCERA VERSIÓN (CLUSTER DE ELEMENTOS+ACELERACIÓN ALGORITMO Bron–Kerbosch)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEPVAGzYTN8D"
      },
      "source": [
        "class Node(object):\n",
        "    def __init__(self, name, coordenadas, puntos):\n",
        "        self.name = name\n",
        "        self.neighbors = []\n",
        "        self.coordenadas = coordenadas\n",
        "        self.x1x2y1y2 = puntos\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.name\n",
        "    \n",
        "def find_cliques(potential_clique=[], remaining_nodes=[], skip_nodes=[], depth=0,lista_cliques=[]):\n",
        "    if len(remaining_nodes) == 0 and len(skip_nodes) == 0:\n",
        "        lista_cliques.append(potential_clique)\n",
        "        return 1\n",
        "    found_cliques = 0\n",
        "    for node in remaining_nodes:\n",
        "        new_potential_clique = potential_clique + [node]\n",
        "        new_remaining_nodes = [n for n in remaining_nodes if n in node.neighbors]\n",
        "        new_skip_list = [n for n in skip_nodes if n in node.neighbors]\n",
        "        found_cliques += find_cliques(new_potential_clique, new_remaining_nodes, new_skip_list, depth + 1,lista_cliques)\n",
        "        remaining_nodes.remove(node)\n",
        "        skip_nodes.append(node)\n",
        "    return found_cliques\n",
        "\n",
        "'''FUNCIÓN DEFINIDA PARA CALCULAR EL CENTROIDE DE ACUERDO CON UNA SERIE DE PUNTOS'''\n",
        "def centroid1(points):\n",
        "    x_coords = [p[0] for p in points]\n",
        "    y_coords = [p[1] for p in points]\n",
        "    _len = len(points)\n",
        "    centroid_x = sum(x_coords)/_len\n",
        "    centroid_y = sum(y_coords)/_len\n",
        "    return [centroid_x, centroid_y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUM5CfQvTN8D"
      },
      "source": [
        "def make_simple_inference_SR(image,counter,x1,y1,width,height,auxiliar_tiempos, LISTA_TRIPLAS):\n",
        "  print('Running super-inference for {}... '.format(image), end='\\n')\n",
        "  \n",
        "  dpi = 300\n",
        "  image2 = np.array(Image.open(image))\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "  \n",
        "  '''OBTENEMOS LAS DETECCIONES PARA LA SUBIMAGEN SUPER-RESUELTA'''\n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "    \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "  \n",
        "  '''FILTRAMOS POR UNA PUNTUACIÓN MÍNIMA PRE-ESTABLECIDA'''\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "  min_score_thresh = .4\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = true_boxes\n",
        "  detections['detection_classes'] = true_clases\n",
        "  detections['detection_scores'] = true_scores\n",
        "    \n",
        "  '''MOSTRAMOS LAS DETECCIONES OBTENIDAS EN LA SUBIMAGEN Y POSTERIORMENTE LA ALMACENAMOS'''\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image2,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=detections.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=1)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image2)\n",
        "\n",
        "  min_score_thresh=.4\n",
        "  nombre = counter\n",
        "  plt.savefig('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/FotoAux/'+str(nombre),  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "  \n",
        "  '''CREAMOS LA LISTA QUE CONFORMARÁN LA TUPLA DE DETECCIONES'''\n",
        "  LISTA_BOXES_TRIPLAS = []\n",
        "  LISTA_CLASES_TRIPLAS = []\n",
        "  LISTA_SCORES_TRIPLAS = []\n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "\n",
        "      ymin11 = ((((box_detected[0]*height))+y1)/2)\n",
        "      xmin11 = ((((box_detected[1]*width))+x1)/2)\n",
        "      ymax11 = ((((box_detected[2]*height))+y1)/2)\n",
        "      xmax11 = ((((box_detected[3]*width))+x1)/2)\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11/height)\n",
        "      coordenadas_good.append(xmin11/width)\n",
        "      coordenadas_good.append(ymax11/height)\n",
        "      coordenadas_good.append(xmax11/width)\n",
        "        \n",
        "      LISTA_BOXES_TRIPLAS.append(coordenadas_good)\n",
        "      LISTA_CLASES_TRIPLAS.append(true_clases[i])\n",
        "      LISTA_SCORES_TRIPLAS.append(true_scores[i])\n",
        "      \n",
        "  \n",
        "  \n",
        "  LISTA_TRIPLAS.append((np.array(LISTA_BOXES_TRIPLAS),np.array(LISTA_CLASES_TRIPLAS),np.array(LISTA_SCORES_TRIPLAS)))\n",
        "  \n",
        "  \n",
        "def make_inference_SR(image_path,counter,image_save,contador_veces):\n",
        "  print('Running inference for {}... '.format(image_path), end='\\n')\n",
        "  contador_veces = contador_veces+1\n",
        "  dpi = 300\n",
        "  image2 = np.array(Image.open(image_path))\n",
        "  \n",
        "  '''CREAMOS LA IMAGEN SUPER-RESUELTA'''\n",
        "  createSR(image_path)\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  '''APLICAMOS LAS DETECCIONES A LA IMAGEN DADA COMO ENTRADA'''\n",
        "\n",
        "  start_time = time.time()\n",
        "  detections = detect_fn(input_tensor)\n",
        "  elapsed_time = time.time() - start_time\n",
        "      \n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()} \n",
        "\n",
        "  detections['num_detections'] = num_detections\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  '''FILTRAMOS LAS DETECCIONES EN BASE A UNA PUNTUACIÓN PRE-DEFINIDA'''\n",
        "  min_score_thresh=.2\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "  true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "  true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "  \n",
        "  new_counter = 0\n",
        "  img = cv2.imread(image_path)\n",
        "  im = Image.open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/TensorFlow/DATAPROCESS/0D_SR.png')\n",
        "\n",
        "  contador_final = 0 \n",
        "\n",
        "  img__READ = cv2.imread(image_path)\n",
        "  height, width, channels = img__READ.shape  \n",
        "  contador_veces = contador_veces+len(true_boxes)\n",
        "  array_veces.append(contador_veces)\n",
        "\n",
        "  listado_de_nodos_ok = []    \n",
        "  LISTA_TRIPLAS = []\n",
        "    \n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "      ymin = int(box_detected[0]*height*2)\n",
        "      xmin = int(box_detected[1]*width*2)\n",
        "      ymax = int(box_detected[2]*height*2)\n",
        "      xmax = int(box_detected[3]*width*2)\n",
        "    \n",
        "      ymin11 = (box_detected[0])\n",
        "      xmin11 = (box_detected[1])\n",
        "      ymax11 = (box_detected[2])\n",
        "      xmax11 = (box_detected[3])\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11)\n",
        "      coordenadas_good.append(xmin11)\n",
        "      coordenadas_good.append(ymax11)\n",
        "      coordenadas_good.append(xmax11)\n",
        "      \n",
        "      a1 = (xmin+xmax)//2\n",
        "      a2 = (ymin+ymax)//2\n",
        "\n",
        "      listado_de_nodos_ok.append(Node(str(i),(a1,a2),(xmin,xmax,ymin,ymax)))\n",
        "\n",
        "      new_counter = new_counter+1\n",
        "\n",
        "      '''\n",
        "      a1 y a2 corresponde con las coordenadas del punto, es por ello por lo que\n",
        "      debo almacenar estos valores para posteriormente calcular la distancia\n",
        "      entre los mismos con una formula matematica. Aquella distancia la cual no\n",
        "      supere un umbral predefinido se establece como vecino del nodo\n",
        "      '''\n",
        "\n",
        "  all_nodes = []\n",
        "  for i in range(len(listado_de_nodos_ok)):\n",
        "     NODO_SELECCIONADO_1 = listado_de_nodos_ok[i]\n",
        "     lista_vecinos = []\n",
        "     all_nodes.append(NODO_SELECCIONADO_1)\n",
        "\n",
        "     a1 = NODO_SELECCIONADO_1.coordenadas[0]\n",
        "     a2 = NODO_SELECCIONADO_1.coordenadas[1]\n",
        "\n",
        "     RECORTEX = int(width/2)\n",
        "     RECORTEY = int(height/2)\n",
        "\n",
        "     xmin = a1-RECORTEX\n",
        "     ymin = a2-RECORTEY\n",
        "     xmax = a1+RECORTEX\n",
        "     ymax = a2+RECORTEY\n",
        "      \n",
        "     for o in range(len(listado_de_nodos_ok)):\n",
        "       if i != o:\n",
        "         NODO_SELECCIONADO_2 = listado_de_nodos_ok[o]\n",
        "         x1 = NODO_SELECCIONADO_1.coordenadas[0]\n",
        "         x2 = NODO_SELECCIONADO_2.coordenadas[0]\n",
        "         y1 = NODO_SELECCIONADO_1.coordenadas[1]\n",
        "         y2 = NODO_SELECCIONADO_2.coordenadas[1]\n",
        "\n",
        "         xminb = NODO_SELECCIONADO_2.x1x2y1y2[0]\n",
        "         xmaxb = NODO_SELECCIONADO_2.x1x2y1y2[1]\n",
        "         yminb = NODO_SELECCIONADO_2.x1x2y1y2[2]\n",
        "         ymaxb = NODO_SELECCIONADO_2.x1x2y1y2[3]\n",
        "\n",
        "        \n",
        "\n",
        "         if (xminb > xmin and xmaxb < xmax and yminb > ymin and ymaxb < ymax):\n",
        "           '''AÑADO COMO LISTA DE VECINO'''\n",
        "           lista_vecinos.append(NODO_SELECCIONADO_2)\n",
        "     NODO_SELECCIONADO_1.neighbors = lista_vecinos\n",
        "    \n",
        "\n",
        "  lista_cliques_ok = []\n",
        "  total_cliques = find_cliques(remaining_nodes=all_nodes,lista_cliques=lista_cliques_ok)\n",
        "  \n",
        "  total_cliques = lista_cliques_ok\n",
        "    \n",
        "  contador_veces = contador_veces+len(lista_cliques_ok)\n",
        "  array_veces.append(contador_veces)\n",
        "\n",
        "\n",
        "  for ix in range(len(lista_cliques_ok)):\n",
        "    '''CALCULO EL CENTROIDE DE LOS PUNTOS'''\n",
        "    cliques_index = total_cliques[ix]\n",
        "    lista_coordenadas = []\n",
        "    for ab in range(len(cliques_index)):\n",
        "     coordenadaxyc = cliques_index[ab].coordenadas\n",
        "     lista_coordenadas.append(coordenadaxyc)\n",
        "    centroide = centroid1(lista_coordenadas)\n",
        "\n",
        "    a1 = centroide[0]\n",
        "    a2 = centroide[1]\n",
        "\n",
        "    RECORTEX = int(width/2)\n",
        "    RECORTEY = int(height/2)\n",
        "      \n",
        "    ''''''\n",
        "    im_crop_outside = im.crop((a1-RECORTEX, a2-RECORTEY, a1+RECORTEX, a2+RECORTEY))\n",
        "    nombre_sr_332 =\"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/AUX/{}.jpg\".format(str(ix))\n",
        "    print(nombre_sr_332)\n",
        "    im_crop_outside.save(nombre_sr_332, quality=100)\n",
        "\n",
        "    RECORTEX = int(width/2)\n",
        "    RECORTEY = int(height/2)\n",
        "\n",
        "    'VOLVEMOS A ESTABLECER LA DETECCIÓN DE OBJETOS EN LA NUEVA SUBIMAGEN GENERADA'\n",
        "      \n",
        "    make_simple_inference_SR(nombre_sr_332,new_counter,a1-RECORTEX,a2-RECORTEY,\n",
        "                                           width,height,counter,LISTA_TRIPLAS )\n",
        "      \n",
        "    new_counter = new_counter+1\n",
        "\n",
        "\n",
        "  puntero = 0\n",
        "    \n",
        "  '''GENERAMOS LA LISTA PARA CONFORMAR LA TRIPLA DE LA PASADA INICIAL'''  \n",
        "  LISTA_BOXES_TRIPLAS = []\n",
        "  LISTA_CLASES_TRIPLAS = []\n",
        "  LISTA_SCORES_TRIPLAS = []\n",
        "  contador_triplas = 0\n",
        "\n",
        "  for i in range(len(true_boxes)):\n",
        "      box_detected = true_boxes[i]\n",
        "      ymin = int(box_detected[0]*height*2)\n",
        "      xmin = int(box_detected[1]*width*2)\n",
        "      ymax = int(box_detected[2]*height*2)\n",
        "      xmax = int(box_detected[3]*width*2)\n",
        "    \n",
        "      ymin11 = (box_detected[0])\n",
        "      xmin11 = (box_detected[1])\n",
        "      ymax11 = (box_detected[2])\n",
        "      xmax11 = (box_detected[3])\n",
        "\n",
        "      coordenadas_good = []\n",
        "      coordenadas_good.append(ymin11)\n",
        "      coordenadas_good.append(xmin11)\n",
        "      coordenadas_good.append(ymax11)\n",
        "      coordenadas_good.append(xmax11)\n",
        "        \n",
        "      LISTA_BOXES_TRIPLAS.append(coordenadas_good)\n",
        "      LISTA_CLASES_TRIPLAS.append(true_clases[contador_triplas])\n",
        "      LISTA_SCORES_TRIPLAS.append(true_scores[contador_triplas])\n",
        "    \n",
        "      \n",
        "      contador_triplas = contador_triplas + 1\n",
        "      \n",
        "\n",
        "  LISTA_TRIPLAS.append((np.array(LISTA_BOXES_TRIPLAS),np.array(LISTA_CLASES_TRIPLAS),np.array(LISTA_SCORES_TRIPLAS)))\n",
        "\n",
        "  \n",
        "  '''OBTENEMOS EL CLUSTER DE ELEMENTOS'''\n",
        "  cluster_final = create_clusters(LISTA_TRIPLAS, threshold =0.1)\n",
        "\n",
        "  \n",
        "  '''\n",
        "  EN BASE A LA LISTA DE TRUPLAS QUE DEVUELVE LA FUNCIÓN CREATE_CLUSTER,\n",
        "  SELECCIONAMOS A LOS ELEMENTOS CON MAYOR PUNTUACIÓN.  \n",
        "  '''\n",
        "\n",
        "  LISTA_BOXES_OK = []\n",
        "  LISTA_CLASES_OK = []\n",
        "  LISTA_SCORES_OK = []\n",
        "    \n",
        "  for indexcluster in range(len(cluster_final)):\n",
        "    tripla = cluster_final[indexcluster]\n",
        "    \n",
        "    lista_boxes_lista = tripla[0].tolist()\n",
        "    lista_clases_lista = tripla[1].tolist()\n",
        "    lista_scores_lista = tripla[2].tolist()\n",
        "    \n",
        "    indice = np.argmax(lista_scores_lista)\n",
        "    \n",
        "    LISTA_BOXES_OK.append(lista_boxes_lista[indice])\n",
        "    LISTA_CLASES_OK.append(lista_clases_lista[indice])\n",
        "    LISTA_SCORES_OK.append(lista_scores_lista[indice])\n",
        "      \n",
        "            \n",
        "  detections['detection_boxes'] = np.array(LISTA_BOXES_OK)\n",
        "  detections['detection_classes'] = np.array(LISTA_CLASES_OK)\n",
        "  detections['detection_scores'] = np.array(LISTA_SCORES_OK)\n",
        "\n",
        "  boxes_filter = []\n",
        "  scores_filter = []\n",
        "  classes_filter = []\n",
        "\n",
        "  for item in range(len(detections['detection_boxes'])):\n",
        "      boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "      scores_filter.append(detections['detection_scores'][item])\n",
        "      classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "  detections['detection_boxes'] = np.array(boxes_filter)\n",
        "  detections['detection_classes'] = np.array(classes_filter)\n",
        "  detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "     \n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image2,\n",
        "      detections['detection_boxes'],\n",
        "      detections['detection_classes'],\n",
        "      detections['detection_scores'],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=300,\n",
        "      min_score_thresh=.3,\n",
        "      agnostic_mode=False,\n",
        "      line_thickness=1)\n",
        "\n",
        "  display(Image.fromarray(image2))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image2)\n",
        "  \n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "  clases_detected = detections['detection_classes']\n",
        "\n",
        "  min_score_thresh=.3\n",
        "  img = cv2.imread(image_path)\n",
        "  nombre = counter\n",
        "  plt.savefig('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/'+nombre,  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "  plt.clf()\n",
        "\n",
        "  boxes = detections['detection_boxes']\n",
        "  scores = detections['detection_scores'],\n",
        "\n",
        "  clases_detected = detections['detection_classes']\n",
        "  \n",
        "  '''DEVOLVEMOS EN LA VARIABLE SALIDA LAS BBOXES, CLASES Y PUNTUACIONES FINALES OBTENIDAS'''\n",
        "  min_score_thresh = .3\n",
        "  salida = []\n",
        "  salida.append(boxes.tolist())\n",
        "  salida.append(scores[0])\n",
        "  salida.append(clases_detected) \n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  width, height = image.size\n",
        "\n",
        "  salida.append(width)\n",
        "  salida.append(height)\n",
        "  return salida\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TioDSiAsTN8F"
      },
      "source": [
        "make_inference_SR('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/1.jpg','1.jpg','/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/',0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10G10VQnTN8F"
      },
      "source": [
        "# **CREACIÓN DEL JSON MODIFICADO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anDTBgqXTN8G"
      },
      "source": [
        "imagenes_dir2 = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images/'\n",
        "contenido2 = os.listdir(imagenes_dir2)\n",
        "imagenes_dir2 = []\n",
        "counter = 0\n",
        "result = []\n",
        "create_dir('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/')\n",
        "create_dir('usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/AUX/')\n",
        "\n",
        "tiempos_procesamiento2 = []\n",
        "auxiliar_tiempos\n",
        "array_veces = []\n",
        "tiempos_procesar2 = []\n",
        "\n",
        "out = []\n",
        "concon = 0\n",
        "'''RECORRO LAS IMÁGENES ALMACENADAS EN UN DIRECTORIO'''\n",
        "for fichero2 in contenido2:\n",
        "  x = re.search(\"[1-9]+[0-9]*\", fichero2)\n",
        "  id = x.group(0)\n",
        "  image_path_gg = \"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images/{}\".format(fichero2)\n",
        "  print(image_path_gg)\n",
        "  contador_veces = 0\n",
        "  \n",
        "  start_time = time.time()\n",
        "  salida = make_inference_SR(image_path_gg,fichero2,'/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/',contador_veces)\n",
        "  \n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  tiempos_procesamiento2.append(elapsed_time)\n",
        "\n",
        "  counter = counter+1\n",
        "  result = []\n",
        "  '''OBTENGO EL ÍNDICE PERTENECIENTE A DICHA IMAGEN'''\n",
        "  converted_num = int(id)\n",
        "  converted_num = diccionario_ids[fichero2]\n",
        "\n",
        "  width = salida[3]\n",
        "  height = salida[4]\n",
        "  boxes2 = []\n",
        "\n",
        "  '''REALIZO LA TRANSOFORMACIÓN DE COORDENADAS DE ACUERDO CON EL FORMATO DE COCO'''\n",
        "  for box in salida[0]:\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "    box_new = []\n",
        "    box_new.append(xmin)\n",
        "    box_new.append(ymin)\n",
        "    box_new.append(xmax-xmin)\n",
        "    box_new.append(ymax-ymin)\n",
        "  \n",
        "\n",
        "    boxes2.append(box_new)\n",
        "  \n",
        "  '''LOS ALMACENO EN UN JSON'''\n",
        "  result.extend(\n",
        "        [\n",
        "            {\n",
        "                \"image_id\": converted_num,\n",
        "                \"category_id\": int(salida[2][k]),\n",
        "                \"bbox\": box,\n",
        "                \"score\": salida[1][k].astype(float),\n",
        "            }\n",
        "            for k, box in enumerate(boxes2)\n",
        "        ]\n",
        "  )\n",
        "  \n",
        "  for sample in result:    \n",
        "        out.append(sample)\n",
        "\n",
        "'''GUARDO EL JSON EN UN ARCHIVO'''\n",
        "with open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/test_data_modificado-VIDEO2.json', 'w', encoding='utf-8') as file:\n",
        "  json.dump(out, file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nu-OSflTN8I"
      },
      "source": [
        "# **EVALUACIÓN DE LAS ANOTACIONES MODIFICADAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dhugacVTN8I"
      },
      "source": [
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "\n",
        "annType = ['segm','bbox','keypoints']\n",
        "annType = annType[1]      #specify type here\n",
        "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
        "print ('Running demo for *%s* results.'%(annType))\n",
        "\n",
        "'''CARGO EL JSON CON LOS GROUND TRUTH (GT)'''\n",
        "annFile = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video3/annotations/instances_default.json'\n",
        "cocoGt=COCO(annFile)\n",
        "\n",
        "'''CARGO EL JSON CON LAS DETECCIONES OBTENIDAS CON LA PROPUESTA EXCLUSIVA DE SR'''\n",
        "resFile = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS_SR/test_data_modificado-VIDEO3.json'\n",
        "cocoDt=cocoGt.loadRes(resFile)\n",
        "\n",
        "dts = json.load(open(resFile,'r'))\n",
        "imgIds = [imid['image_id'] for imid in dts]\n",
        "imgIds = sorted(list(set(imgIds)))\n",
        "\n",
        "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "cocoEval.params.imgIds  = imgIds\n",
        "'''SELECCIONO LA CLASE 3 CORRESPONDIENTE CON LOS COCHES'''\n",
        "cocoEval.params.catIds = [3] \n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blXIXHOYTN8I"
      },
      "source": [
        "# **DIBUJAR LOS GT CON LAS ANOTACIONES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf2cdbHnTN8I"
      },
      "source": [
        "def create_image(image_path,counter):\n",
        "  imga = cv2.imread(image_path)\n",
        "  nombrenuevo = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/valGT/'+counter\n",
        "  cv2.imwrite(nombrenuevo, imga)\n",
        "  return nombrenuevo\n",
        "\n",
        "def draw_rectangle(image_path,x1,y1,x2,y2):\n",
        "  x1 = round(x1)\n",
        "  y1 = round(y1)\n",
        "  x2 = round(x2)\n",
        "  y2 = round(y2)\n",
        "\n",
        "  start_point = (x1, y1) \n",
        "  end_point = (x1+x2, y1+y2) \n",
        "  color = (255, 0, 0) \n",
        "  thickness = 2   \n",
        "\n",
        "  imga = cv2.imread(image_path)\n",
        "  image = cv2.rectangle(imga, start_point, end_point, color, thickness) \n",
        "  cv2.imwrite(image_path, imga)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lh4WgImTN8J"
      },
      "source": [
        "jsonString = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/annotations/instances_default.json'\n",
        "images_dir_dataprocess = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/valGT/'\n",
        "create_dir(images_dir_dataprocess)\n",
        "\n",
        "contenido2 = os.listdir('/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images')\n",
        "contador = 0\n",
        "for fichero in contenido2:\n",
        "  nombre_good = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images/'+fichero \n",
        "  id_frame = diccionario_ids[fichero]\n",
        "  salida = create_image(nombre_good,fichero)\n",
        "  contador=contador+1\n",
        "  with open(jsonString) as json_file:\n",
        "      data = json.load(json_file)\n",
        "      for p3 in data['annotations']:\n",
        "          nombre_identificador = p3['image_id']\n",
        "          if nombre_identificador == id_frame:\n",
        "            lista = p3['bbox']\n",
        "            draw_rectangle(salida,lista[0],lista[1],lista[2],lista[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4X3cLA-TN8O"
      },
      "source": [
        "# **TRANSFER-LEARNING -> (Fine-Tuning)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHuWEYngbXFe"
      },
      "source": [
        "### FUNCIONES AUXILIARES DEFINIDAS PARA LA CREACIÓN DE LOS XML DE FORMA AUTOMÁTICA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXJPrG0GTN8P"
      },
      "source": [
        "start_ranges = \"|\".join(\n",
        "    \"[{0}]\".format(r)\n",
        "    for r in [\n",
        "        \"\\xC0-\\xD6\",\n",
        "        \"\\xD8-\\xF6\",\n",
        "        \"\\xF8-\\u02FF\",\n",
        "        \"\\u0370-\\u037D\",\n",
        "        \"\\u037F-\\u1FFF\",\n",
        "        \"\\u200C-\\u200D\",\n",
        "        \"\\u2070-\\u218F\",\n",
        "        \"\\u2C00-\\u2FEF\",\n",
        "        \"\\u3001-\\uD7FF\",\n",
        "        \"\\uF900-\\uFDCF\",\n",
        "        \"\\uFDF0-\\uFFFD\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "NameStartChar = re.compile(r\"(:|[A-Z]|_|[a-z]|{0})\".format(start_ranges))\n",
        "NameChar = re.compile(r\"(\\-|\\.|[0-9]|\\xB7|[\\u0300-\\u036F]|[\\u203F-\\u2040])\")\n",
        "\n",
        "class Node(object):\n",
        "    entities = [(\"&\", \"&amp;\"), (\"<\", \"&lt;\"), (\">\", \"&gt;\")]\n",
        "\n",
        "    def __init__(self, wrap=\"\", tag=\"\", data=None, iterables_repeat_wrap=True):\n",
        "        self.tag = self.sanitize_element(tag)\n",
        "        self.wrap = self.sanitize_element(wrap)\n",
        "        self.data = data\n",
        "        self.type = self.determine_type()\n",
        "        self.iterables_repeat_wrap = iterables_repeat_wrap\n",
        "\n",
        "        if self.type == \"flat\" and isinstance(self.data, str):\n",
        "            for entity, replacement in self.entities:\n",
        "                self.data = self.data.replace(entity, replacement)\n",
        "\n",
        "    def serialize(self, indenter):\n",
        "        wrap = self.wrap\n",
        "        end, start = \"\", \"\"\n",
        "        if wrap:\n",
        "            end = \"</{0}>\".format(wrap)\n",
        "            start = \"<{0}>\".format(wrap)\n",
        "\n",
        "        value, children = self.convert()\n",
        "\n",
        "        content = \"\"\n",
        "        if children:\n",
        "            if self.type != \"iterable\":\n",
        "                content = indenter((c.serialize(indenter) for c in children), wrap)\n",
        "            else:\n",
        "                if self.iterables_repeat_wrap:\n",
        "                    result = []\n",
        "                    for c in children:\n",
        "                        content = c.serialize(indenter)\n",
        "                        if c.type == \"flat\":\n",
        "                            result.append(content)\n",
        "                        else:\n",
        "                            content = indenter([content], True)\n",
        "                            result.append(\"\".join((start, content, end)))\n",
        "\n",
        "                    return indenter(result, False)\n",
        "                else:\n",
        "                    result = []\n",
        "                    for c in children:\n",
        "                        result.append(c.serialize(indenter))\n",
        "                    return \"\".join([start, indenter(result, True), end])\n",
        "\n",
        "        \n",
        "        return \"\".join((start, value, content, end))\n",
        "\n",
        "    def determine_type(self):\n",
        "        \n",
        "        data = self.data\n",
        "        if isinstance(data, str):\n",
        "            return \"flat\"\n",
        "        elif isinstance(data, collections.abc.Mapping):\n",
        "            return \"mapping\"\n",
        "        elif isinstance(data, collections.abc.Iterable):\n",
        "            return \"iterable\"\n",
        "        else:\n",
        "            return \"flat\"\n",
        "\n",
        "    def convert(self):\n",
        "        \n",
        "        val = \"\"\n",
        "        typ = self.type\n",
        "        data = self.data\n",
        "        children = []\n",
        "\n",
        "        if typ == \"mapping\":\n",
        "            sorted_data = data\n",
        "            if not isinstance(data, collections.OrderedDict):\n",
        "                sorted_data = (data)\n",
        "\n",
        "            for key in sorted_data:\n",
        "                item = data[key]\n",
        "                children.append(\n",
        "                    Node(key, \"\", item, iterables_repeat_wrap=self.iterables_repeat_wrap)\n",
        "                )\n",
        "\n",
        "        elif typ == \"iterable\":\n",
        "            for item in data:\n",
        "                children.append(\n",
        "                    Node(\"\", self.wrap, item, iterables_repeat_wrap=self.iterables_repeat_wrap,)\n",
        "                )\n",
        "\n",
        "        else:\n",
        "            val = str(data)\n",
        "            if self.tag:\n",
        "                val = \"<{0}>{1}</{2}>\".format(self.tag, val, self.tag)\n",
        "\n",
        "        return val, children\n",
        "\n",
        "    @staticmethod\n",
        "    def sanitize_element(wrap):\n",
        "        \n",
        "        if wrap and isinstance(wrap, str):\n",
        "            if wrap.lower().startswith(\"xml\"):\n",
        "                wrap = \"_\" + wrap\n",
        "            return \"\".join(\n",
        "                [\"_\" if not NameStartChar.match(wrap) else \"\"]\n",
        "                + [\"_\" if not (NameStartChar.match(c) or NameChar.match(c)) else c for c in wrap]\n",
        "            )\n",
        "        else:\n",
        "            return wrap\n",
        "\n",
        "class Converter(object):\n",
        "    \n",
        "\n",
        "    def __init__(self, wrap=None, indent=\"  \", newlines=True):\n",
        "        \n",
        "        self.wrap = wrap\n",
        "        self.indent = indent\n",
        "        self.newlines = newlines\n",
        "\n",
        "    def _make_indenter(self):\n",
        "        indent = self.indent\n",
        "        newlines = self.newlines\n",
        "\n",
        "        if not newlines:\n",
        "            ret = lambda nodes, wrapped: \"\".join(nodes)\n",
        "        else:\n",
        "            if not indent:\n",
        "                indent = \"\"\n",
        "\n",
        "            def eachline(nodes):\n",
        "                for node in nodes:\n",
        "                    for line in node.split(\"\\n\"):\n",
        "                        yield line\n",
        "\n",
        "            def ret(nodes, wrapped):\n",
        "                if wrapped:\n",
        "                    seperator = \"\\n{0}\".format(indent)\n",
        "                    surrounding = \"\\n{0}{{0}}\\n\".format(indent)\n",
        "                else:\n",
        "                    seperator = \"\\n\"\n",
        "                    surrounding = \"{0}\"\n",
        "                return surrounding.format(seperator.join(eachline(nodes)))\n",
        "\n",
        "        return ret\n",
        "\n",
        "    def build(self, data, iterables_repeat_wrap=True):\n",
        "        indenter = self._make_indenter()\n",
        "        return Node(\n",
        "            wrap=self.wrap, data=data, iterables_repeat_wrap=iterables_repeat_wrap\n",
        "        ).serialize(indenter)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t--TmDisb2lG"
      },
      "source": [
        "### FUNCIÓN DEFINIDA PARA TRANSFORMAR UN DICCIONARIO EN UN ARCHIVO XML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D3OxuveTN8Q"
      },
      "source": [
        "def dict2xml(data, *args, **kwargs):\n",
        "    return Converter(*args, **kwargs).build(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_zU8kzSb8sR"
      },
      "source": [
        "### EJEMPLO DE PRUEBA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKJr9sXnTN8Q"
      },
      "source": [
        "\n",
        "json = {\n",
        "  \"annotation\": {\n",
        "    \"folder\": \"images\",\n",
        "    \"filename\": \"1.jpg\",\n",
        "    \"path\": \"/Users/ivan/Desktop/images/1.jpg\",\n",
        "    \"source\": {\n",
        "      \"database\": \"Unknown\"\n",
        "    },\n",
        "    \"size\": {\n",
        "      \"width\": \"640\",\n",
        "      \"height\": \"480\",\n",
        "      \"depth\": \"3\"\n",
        "    },\n",
        "    \"segmented\": \"0\",\n",
        "    \"object\": [\n",
        "      {\n",
        "        \"name\": \"car\",\n",
        "        \"pose\": \"Unspecified\",\n",
        "        \"truncated\": \"0\",\n",
        "        \"difficult\": \"0\",\n",
        "        \"bndbox\": {\n",
        "          \"xmin\": \"302\",\n",
        "          \"ymin\": \"215\",\n",
        "          \"xmax\": \"338\",\n",
        "          \"ymax\": \"237\"\n",
        "        }\n",
        "      },\n",
        "      {\n",
        "        \"name\": \"car\",\n",
        "        \"pose\": \"Unspecified\",\n",
        "        \"truncated\": \"0\",\n",
        "        \"difficult\": \"0\",\n",
        "        \"bndbox\": {\n",
        "          \"xmin\": \"417\",\n",
        "          \"ymin\": \"199\",\n",
        "          \"xmax\": \"453\",\n",
        "          \"ymax\": \"222\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}\n",
        "print(dict2xml(json))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FQTifMTN8R"
      },
      "source": [
        "# **CREACIÓN DE LOS RESPECTIVOS XML**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIWEsTjBTN8R"
      },
      "source": [
        "\n",
        "imagenes_dir2 = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/IMAGENES'\n",
        "contenido2 = os.listdir(imagenes_dir2)\n",
        "imagenes_dir2 = []\n",
        "counter = 0\n",
        "result = []\n",
        "create_dir('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/RESULTADOS_SR')\n",
        "\n",
        "tiempos_procesamiento2 = []\n",
        "out = []\n",
        "concon = 0\n",
        "\n",
        "'''RECORRO LAS IMÁGENES ALMACENADAS EN EL DIRECTORIO DADO COMO ENTRADA'''\n",
        "\n",
        "for fichero2 in contenido2:\n",
        "  create_dir('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/AUX')\n",
        "  concon = concon +1\n",
        "  x = re.search(\"[1-9]+[0-9]*\", fichero2)\n",
        "  id = x.group(0)\n",
        "  image_path_gg = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/IMAGENES/{}\".format(fichero2)\n",
        "  image_path_gg2 = \"/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/ARCHIVOS/{}\".format(fichero2)\n",
        "  print(image_path_gg)\n",
        "  start_time = time()\n",
        "  \n",
        "  elapsed_time = time() - start_time\n",
        "  tiempos_procesamiento2.append(elapsed_time)\n",
        "  salida = make_inference_SR(image_path_gg,fichero2,'/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/RESULTADOS_SR/')\n",
        "  print(\"\\n\")\n",
        "  counter = counter+1\n",
        "  result = []\n",
        "  \n",
        "  width = salida[3]\n",
        "  height = salida[4]\n",
        "\n",
        "  x = '{\"annotation\":{\"folder\": \"images\",\"filename\": \"1.jpg\",\"path\": \"/Users/ivan/Desktop/images/1.jpg\",\"source\": {\"database\": \"Unknown\"},\"size\": {\"width\": \"640\",\"height\": \"480\",\"depth\": \"3\"},\"segmented\": \"0\",\"object\": []}}'\n",
        "  y = json.loads(x)\n",
        "  y[\"annotation\"][\"folder\"] = 'IMAGENES'\n",
        "  y[\"annotation\"][\"filename\"] = fichero2\n",
        "  y[\"annotation\"][\"path\"] = image_path_gg\n",
        "  y[\"annotation\"][\"size\"][\"width\"] = width\n",
        "  y[\"annotation\"][\"size\"][\"height\"] = height\n",
        "\n",
        "  shutil.copyfile(image_path_gg, image_path_gg2)\n",
        "  boxes2 = []\n",
        "\n",
        "  for box in salida[0]:\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "    objeto1 = '{\"name\": \"car\",\"pose\": \"Unspecified\",\"truncated\": \"0\",\"difficult\": \"0\",\"bndbox\": {\"xmin\": \"302\",\"ymin\": \"215\",\"xmax\": \"338\",\"ymax\": \"237\"}}'\n",
        "    z = json.loads(objeto1)\n",
        "    z[\"name\"] = \"car\"\n",
        "    z[\"bndbox\"][\"xmin\"] = xmin \n",
        "    z[\"bndbox\"][\"xmax\"] = xmax\n",
        "    z[\"bndbox\"][\"ymin\"] = ymin\n",
        "    z[\"bndbox\"][\"ymax\"] = ymax\n",
        "\n",
        "    y['annotation']['object'].append(z)\n",
        "\n",
        "  nombre_bueno = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/IMAGENES_JSON/'+id+'.json'\n",
        "  nombre_bueno2 = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/ARCHIVOS/'+id+'.xml'\n",
        "  print(y)\n",
        "  with open(nombre_bueno, 'w', encoding='utf-8') as f:\n",
        "    json.dump(y, f)\n",
        "\n",
        "  '''hacerlo en xml'''\n",
        "  with open(nombre_bueno) as json_file:\n",
        "    data = json.load(json_file)\n",
        "    xml = dict2xml(data)\n",
        "    with open(nombre_bueno2, \"w\") as f:\n",
        "      f.write(xml)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt9mjxcLTN8U"
      },
      "source": [
        "# **SEPARACIÓN DE ARCHIVOS DE ENTRENAMIENTO Y VALIDACIÓN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrMsCoPQTN8V"
      },
      "source": [
        "!python '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/SCRIPTS/partition_dataset.py' -x -i /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/ARCHIVOS -r 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC_hBganTN8V"
      },
      "source": [
        "# **GENERACIÓN DE LOS TFRECORDS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIeWsFB8TN8V"
      },
      "source": [
        "!python '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/SCRIPTS/generate_tfrecord.py' -x /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/ARCHIVOS/train -l /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/LABELMAP/label_map.pbtxt -o /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/RECORD-TRAIN/train.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVIxY91TN8V"
      },
      "source": [
        "!python '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/SCRIPTS/generate_tfrecord.py' -x /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/ARCHIVOS/test -l /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/LABELMAP/label_map.pbtxt -o /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/RECORD-TEST/test.record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY3C_X7XTN8W"
      },
      "source": [
        "# **DESCARGA Y CONFIGURACIÓN DEL MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9tv6Mu2TN8X"
      },
      "source": [
        "cd /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/PRE-TRAINED"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke5FSOoZTN8X"
      },
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d4_coco17_tpu-32.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai42CD1sTN8X"
      },
      "source": [
        "!tar xvzf /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/TRAIN/PRE-TRAINED/efficientdet_d4_coco17_tpu-32.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwHQ8_fOTN8Y"
      },
      "source": [
        "# **COMIENZO DEL ENTRENAMIENTO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyKosN6aTN8a"
      },
      "source": [
        "!python /usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/SCRIPTS/model_main_tf2.py --model_dir=/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/MIS-MODELOS/myEfficient --pipeline_config_path=/usr/share/Data2/objectos_pequeños/PRINCIPAL/RENTRENAMIENTO/MIS-MODELOS/myEfficient/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE6kmVkiTN8a"
      },
      "source": [
        "# **EVALUACIÓN DE LOS MODELOS CKPT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NwFSO1yTN8b"
      },
      "source": [
        "PATH_TO_CFG = \"/home/ivangarcia/Desktop/MisModelos/efficientd4mod/ssd_efficientdet_d4_1024x1024_coco17_tpu-32.config\"\n",
        "PATH_TO_CKPT = \"/home/ivangarcia/Desktop/MisModelos/efficientd4mod\"\n",
        "\n",
        "print('Loading model... ', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrrX9ad-TN8b"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWPSwTOuTN8b"
      },
      "source": [
        "def make_checkpoint_final(image_path,counter,image_save):\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "    image_np_with_detections = image_np.copy()\n",
        "    \n",
        "    boxes_filter = []\n",
        "    scores_filter = []\n",
        "    classes_filter = []\n",
        "\n",
        "    for item in range(len(detections['detection_boxes'])):\n",
        "        boxes_filter.append(detections['detection_boxes'][item].tolist())\n",
        "        scores_filter.append(detections['detection_scores'][item])\n",
        "        classes_filter.append(detections['detection_classes'][item])\n",
        "\n",
        "\n",
        "    detections['detection_boxes'] = np.array(boxes_filter)\n",
        "    detections['detection_classes'] = np.array(classes_filter)\n",
        "    detections['detection_scores'] = np.array(scores_filter)\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.4,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    nombre = counter\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    plt.savefig(image_save+nombre,  dpi=dpi ,bbox_inches='tight',pad_inches = 0)\n",
        "\n",
        "    plt.clf()\n",
        "\n",
        "    boxes = detections['detection_boxes']\n",
        "    scores = detections['detection_scores'],\n",
        "    clases_detected = detections['detection_classes']\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    boxes = detections['detection_boxes']\n",
        "    scores = detections['detection_scores'],\n",
        "    clases_detected = detections['detection_classes']\n",
        "\n",
        "    min_score_thresh = .3\n",
        "    true_boxes  = boxes[scores[0] > min_score_thresh]\n",
        "    true_scores = scores[0][scores[0] > min_score_thresh]\n",
        "    true_clases = clases_detected[scores[0] > min_score_thresh]\n",
        "\n",
        "    salida = []\n",
        "    salida.append(true_boxes.tolist())\n",
        "    salida.append(true_scores.tolist())\n",
        "    salida.append(true_clases.tolist()) \n",
        "\n",
        "    image = Image.open(image_path)\n",
        "    width, height = image.size\n",
        "\n",
        "    salida.append(width)\n",
        "    salida.append(height)\n",
        "\n",
        "    return salida\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcP6cjBWTN8b"
      },
      "source": [
        "import re\n",
        "imagenes_dir2 = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images'\n",
        "contenido2 = os.listdir(imagenes_dir2)\n",
        "imagenes_dir2 = []\n",
        "counter = 0\n",
        "result = []\n",
        "tiempos_procesar = []\n",
        "\n",
        "out = []\n",
        "concon = 0\n",
        "for fichero2 in contenido2:\n",
        "  print(concon)\n",
        "  concon = concon +1\n",
        "  x = re.search(\"[1-9]+[0-9]*\", fichero2)\n",
        "  id = x.group(0)\n",
        "  print(id)\n",
        "  image_path_gg = \"/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/images/{}\".format(fichero2)\n",
        "  start_time = time()\n",
        "  salida = make_checkpoint_final(image_path_gg,fichero2,'/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/')\n",
        "  elapsed_time = time() - start_time\n",
        "  tiempos_procesar.append(elapsed_time)\n",
        "  result = []\n",
        "  converted_num = int(id)\n",
        "  converted_num = diccionario_ids[fichero2]\n",
        "  print(fichero2, \" \",converted_num)\n",
        "\n",
        "  width = salida[3]\n",
        "  height = salida[4]\n",
        "\n",
        "  boxes2 = []\n",
        "\n",
        "  for box in salida[0]:\n",
        "    ymin = int(box[0]*height)\n",
        "    xmin = int(box[1]*width)\n",
        "    ymax = int(box[2]*height)\n",
        "    xmax = int(box[3]*width) \n",
        "\n",
        "\n",
        "    box_new = []\n",
        "    box_new.append(xmin)\n",
        "    box_new.append(ymin)\n",
        "    box_new.append(xmax-xmin)\n",
        "    box_new.append(ymax-ymin)\n",
        "  \n",
        "\n",
        "    boxes2.append(box_new)\n",
        "   \n",
        "\n",
        "\n",
        "  result.extend(\n",
        "        [\n",
        "            {\n",
        "                \"image_id\": converted_num,\n",
        "                \"category_id\": salida[2][k],\n",
        "                \"bbox\": box,\n",
        "                \"score\": salida[1][k],\n",
        "            }\n",
        "            for k, box in enumerate(boxes2)\n",
        "        ]\n",
        "  )\n",
        "  \n",
        "  for sample in result:    \n",
        "        out.append(sample)#detection result including \n",
        "\n",
        "with open('/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/test_data_normal.json', 'w', encoding='utf-8') as file:\n",
        "  json.dump(out, file, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj_PbTGYTN8c"
      },
      "source": [
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "\n",
        "\n",
        "annType = ['segm','bbox','keypoints']\n",
        "annType = annType[1]      #specify type here\n",
        "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
        "print ('Running demo for *%s* results.'%(annType))\n",
        "\n",
        "annFile = '/usr/share/Data2/objectos_pequeños/FOTOSYEVAULACION/video1/annotations/instances_default.json'\n",
        "cocoGt=COCO(annFile)\n",
        "\n",
        "resFile = '/usr/share/Data2/objectos_pequeños/PRINCIPAL/RESULTADOS/test_data_normal.json'\n",
        "cocoDt=cocoGt.loadRes(resFile)\n",
        "\n",
        "dts = json.load(open(resFile,'r'))\n",
        "imgIds = [imid['image_id'] for imid in dts]\n",
        "imgIds = sorted(list(set(imgIds)))\n",
        "\n",
        "\n",
        "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
        "cocoEval.params.imgIds  = imgIds\n",
        "cocoEval.params.catIds = [3] \n",
        "cocoEval.evaluate()\n",
        "cocoEval.accumulate()\n",
        "cocoEval.summarize()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}